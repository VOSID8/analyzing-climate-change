[0m[[0m[0mdebug[0m] [0m[0m> Exec(run, Some(36143f95-da93-458f-a4c7-66f4b8abf209), Some(CommandSource(console0)))[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / run[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 1 Scala source to C:\Projects\NOAAData\noaadata\target\scala-2.12\classes ...[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Projects/NOAAData/noaadata/src/main/scala/semiaridcommon.scala","languageId":"scala","version":27,"text":"\nimport org.apache.spark.sql.SparkSession\nimport scalafx.application.JFXApp\nimport org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.types.StructField\nimport org.apache.spark.sql.types.StringType\nimport org.apache.spark.sql.types.DateType\nimport org.apache.spark.sql.types.DoubleType\nimport org.apache.spark.sql.functions.col\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.functions._\nimport swiftvis2.plotting._\nimport swiftvis2.plotting.ColorGradient\nimport swiftvis2.plotting.renderer.SwingRenderer\n\n\nobject semiaridcommon extends JFXApp {\n  val spark = SparkSession.builder().master(\"local[*]\").appName(\"NOAA Data\").getOrCreate()\n  import spark.implicits._\n  \n  spark.sparkContext.setLogLevel(\"WARN\")\n  \n  val tschema = StructType(Array(\n      StructField(\"sid\",StringType),\n      StructField(\"date\",DateType),\n      StructField(\"mtype\",StringType),\n      StructField(\"value\",DoubleType)\n      ))\n    \n  val data2022 = spark.read.schema(tschema).option(\"dateFormat\", \"yyyyMMdd\").csv(\"src/main/scala/data/2022.csv\").cache()\n  val data1972 = spark.read.schema(tschema).option(\"dateFormat\", \"yyyyMMdd\").csv(\"src/main/scala/data/1972.csv\").cache()\n  \n  val sschema = StructType(Array(\n      StructField(\"sid\", StringType),\n      StructField(\"lat\", DoubleType),\n      StructField(\"lon\", DoubleType),\n      StructField(\"name\", StringType)\n      ))\n  val stationRDD = spark.sparkContext.textFile(\"src/main/scala/data/ghcnd-stations.txt\").map { line =>\n    val id = line.substring(0, 11)\n    val lat = line.substring(12, 20).toDouble\n    val lon = line.substring(21, 30).toDouble\n    val name = line.substring(41, 71)\n    Row(id, lat, lon, name)\n  }\n  val stations = spark.createDataFrame(stationRDD, sschema).cache()\n  \n  val prcp2022 = data2022.filter($\"mtype\" === \"PRCP\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"prcp\")\n  val dailyPrp2022 = prcp2022.select('sid, 'date, ('prcp)/10 as \"pri2022\")\n  val stationPrp2022 = dailyPrp2022.groupBy('sid).agg(avg('pri2022) as \"pri2022\")\n  val joinedData2022 = stationPrp2022.join(stations, \"sid\")\n\n  val prcp1972 = data1972.filter($\"mtype\" === \"PRCP\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"prcp\")\n  val dailyPrp1972 = prcp1972.select('sid, 'date, ('prcp)/10 as \"pri1972\")\n  val stationPrp1972 = dailyPrp1972.groupBy('sid).agg(avg('pri1972) as \"pri1972\")\n  \n  val combinedData = stationPrp1972.join(joinedData2022,\"sid\")\n  \n  //val lons = combinedData.select('lon).as[Double].collect()\n  //val lats = combinedData.select('lat).as[Double].collect()\n\n  val downs = combinedData.filter(col(\"pri1972\") < 500.0)\n  val lonsdowns = downs.select('lon).as[Double].collect()\n  val latsdowns = downs.select('lat).as[Double].collect()\n  val varidowns = downs.select('pri1972).as[Double].collect()\n\n  //val ups = combinedData.filter(col(\"pri2022\") < 500.0)\n  //val lonsups = ups.select('lon).as[Double].collect()\n  //val latsups = ups.select('lat).as[Double].collect()\n  //val variups = ups.select('pri2022).as[Double].collect()\n\n  println(varidowns.length)\n  //println(variups.length)\n  \n  \n  //{\n  //  val cg = ColorGradient(0.0 -> RedARGB)\n  //  val plot1 = Plot.scatterPlot(lonsups, latsups, title = \"Semi-Arid stations in 2022\", xLabel = \"Longitude\", \n  //      yLabel = \"Latitude\", symbolSize = 3, cg(variups))\n  //  SwingRenderer(plot1, 900, 700)\n  //}\n  {\n    val cg = ColorGradient(0.0 -> BlueARGB)\n    val plot2 = Plot.scatterPlot(lonsdowns, latsdowns, title = \"Semi-Arid stations in 1972\", xLabel = \"Longitude\", \n        yLabel = \"Latitude\", symbolSize = 3, cg(varidowns))\n    SwingRenderer(plot2, 900, 700)\n  }\n\nspark.stop()\n}\n\n\n\n\n\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267143475,"message":"Compiling root (15%)","total":26,"progress":15,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267143495,"message":"Compiling root (15%)","total":26,"progress":15,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267143567,"message":"Compiling root (30%)","total":26,"progress":30,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267143568,"message":"Compiling root (30%)","total":26,"progress":30,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267144310,"message":"Compiling root (50%)","total":26,"progress":50,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267144311,"message":"Compiling root (50%)","total":26,"progress":50,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145039,"message":"Compiling root (65%)","total":26,"progress":65,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145039,"message":"Compiling root (65%)","total":26,"progress":65,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145174,"message":"Compiling root (80%)","total":26,"progress":80,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145175,"message":"Compiling root (80%)","total":26,"progress":80,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145909,"message":"Compiling root (100%)","total":26,"progress":100,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskProgress, {"taskId":{"id":"2","parents":[]},"eventTime":1676267145910,"message":"Compiling root (100%)","total":26,"progress":100,"dataKind":"compile-progress","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"}}})[0m
[0m[[0m[33mwarn[0m] [0m[0mthere was one deprecation warning (since 16.0.0-R23); re-run with -deprecation for details[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":2,"message":"there was one deprecation warning (since 16.0.0-R23); re-run with -deprecation for details"})[0m
[0m[[0m[33mwarn[0m] [0m[0mone warning found[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":2,"message":"one warning found"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/semiaridcommon.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tmaxsize.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tmingraph.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/precip2022.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Size.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tmin.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/precipcommon.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Ditemp2022.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Ditempcommon.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tmaxgraph.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tmax.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Ditempgraph.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Ditemp1972.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/Ditempindi.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Projects/NOAAData/noaadata/src/main/scala/tminsize.scala"},"buildTarget":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"diagnostics":[],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskFinish, {"taskId":{"id":"2","parents":[]},"eventTime":1676267146107,"message":"Compiled root","status":1,"dataKind":"compile-report","data":{"target":{"uri":"file:/C:/Projects/NOAAData/noaadata/#root/Compile"},"errors":0,"warnings":0,"time":14961}})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":3,"message":"running semiaridcommon "})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":4,"message":"  Classpath:\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\job-1\\target\\fb7cf167\\50191d9d\\datav_2.12-0.1.0-SNAPSHOT.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1a6dc66b\\4087f4ae\\swiftvis2core_2.12-0.1.0-SNAPSHOT.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\bdcb5394\\a298f006\\swiftvis2fx_2.12-0.1.0-SNAPSHOT.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\736912cc\\19ef9c79\\swiftvis2jvm_2.12-0.1.0-SNAPSHOT.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2a2e1f1d\\fffbd686\\swiftvis2swing_2.12-0.1.0-SNAPSHOT.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8698e580\\9adaa3bf\\scala-library-2.12.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e29d134f\\90aece9f\\scalafx_2.12-19.0.0-R30.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9b854169\\977efa4a\\spark-core_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\efe39471\\4ee3c164\\spark-sql_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\868b569d\\49fe73f2\\scala-reflect-2.12.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e369afee\\f109638e\\javafx-base-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7d5fccad\\833fa139\\javafx-controls-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\82ee633f\\bbcbde62\\javafx-fxml-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\4a9583e5\\f8a9af8f\\javafx-graphics-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1c582dd7\\322436f9\\javafx-media-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\12984c46\\f89b3372\\javafx-swing-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7509520f\\5d7fe77d\\javafx-web-19.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f1ffff92\\00928eca\\avro-1.11.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\146cd53e\\13677bcf\\avro-mapred-1.11.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a2b0e5cf\\9035d1e8\\chill_2.12-0.10.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e6b9a350\\5ea1e05e\\chill-java-0.10.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\59895e0c\\37c97945\\xbean-asm9-shaded-4.20.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\252c0593\\dbc63e3b\\hadoop-client-api-3.3.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2384b885\\1137ee31\\hadoop-client-runtime-3.3.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ff71a055\\77ca1ec0\\spark-launcher_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e4da334a\\2ccd8082\\spark-kvstore_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\24bff8a0\\95ed1a51\\spark-network-common_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\bc73d587\\98a8e1d2\\spark-network-shuffle_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\fd2e512f\\d8ba84e5\\spark-unsafe_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\0c8bc2d1\\2359205f\\activation-1.1.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1978ddb6\\00a411fd\\curator-recipes-2.13.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2c43bae3\\a774bbac\\zookeeper-3.6.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1899f9ce\\06263775\\jakarta.servlet-api-4.0.3.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9c66b66d\\4d272b22\\commons-codec-1.15.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\dbc1886b\\398cce1b\\commons-lang3-3.12.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\d1da8658\\13405d18\\commons-math3-3.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6393782d\\c2b7ea7c\\commons-text-1.9.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\819ac81d\\288a5475\\commons-io-2.11.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\afd9366e\\97a86a4a\\commons-collections-3.2.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6e904adc\\ff64622f\\commons-collections4-4.4.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ade9c2c0\\1dddabdd\\jsr305-3.0.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7cedc43d\\bc486f64\\slf4j-api-1.7.35.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\999c9a09\\6d84412a\\jul-to-slf4j-1.7.32.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\875e2d75\\b07829a0\\jcl-over-slf4j-1.7.32.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2046a0e6\\f67577ef\\log4j-slf4j-impl-2.17.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e2ccaa4d\\ac8f19d7\\log4j-api-2.17.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8d646aff\\f36dff7d\\log4j-core-2.17.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\497110c3\\81c09b4d\\log4j-1.2-api-2.17.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ee08a5cd\\7fa694e0\\compress-lzf-1.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e5fde68a\\6b3e2c2e\\snappy-java-1.1.8.4.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a802a411\\fa566c13\\lz4-java-1.8.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\bfdbabb1\\875257f5\\zstd-jni-1.5.2-1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6676307e\\a903a7f9\\RoaringBitmap-0.9.25.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8347de33\\a8dd6669\\scala-xml_2.12-1.2.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a07d2438\\3b9aec93\\json4s-jackson_2.12-3.7.0-M11.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7eb042b8\\0ca115cb\\jersey-client-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\50654eb4\\1fe4316f\\jersey-common-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\334caaa9\\49bf6ba3\\jersey-server-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\406e7d8d\\cafbeecd\\jersey-container-servlet-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\d7e25713\\ffb81f49\\jersey-container-servlet-core-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\3172299c\\a1d76dfe\\jersey-hk2-2.36.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\99f89852\\f0aedfcf\\netty-all-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\37b0cc66\\396c5c01\\stream-2.9.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\85716128\\b1d9a1ce\\metrics-core-4.2.7.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9b5a2f78\\e389488f\\metrics-jvm-4.2.7.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9d75d005\\30050766\\metrics-json-4.2.7.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9ae1222d\\65717468\\metrics-graphite-4.2.7.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\448a289e\\6f39b9ff\\metrics-jmx-4.2.7.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\d7da0b96\\81c0c23a\\jackson-databind-2.13.4.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6e98bf71\\2b7912a4\\jackson-module-scala_2.12-2.13.4.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9b54af81\\7b3fc2a6\\ivy-2.5.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\df9e7f18\\1783d108\\oro-2.0.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\4fdbcd0f\\3074380d\\pickle-1.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f4280e65\\b360a571\\py4j-0.10.9.5.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\faeca6cf\\98334a6e\\spark-tags_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\5d359af8\\736ebebb\\commons-crypto-1.1.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\66034d01\\e703ea1a\\unused-1.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a6623254\\2be6e91c\\rocksdbjni-6.20.3.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\c79196f1\\c76b8500\\univocity-parsers-2.9.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\3ab33f3c\\408a3a07\\spark-sketch_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f1347dd9\\15c32319\\spark-catalyst_2.12-3.3.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\fc452f12\\24277f82\\orc-core-1.7.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1e0d3b44\\1ace3f7a\\orc-mapreduce-1.7.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\60e13d6e\\6a745dbf\\hive-storage-api-2.7.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e37c5bc6\\239eba48\\parquet-column-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f12c8032\\515c08e9\\parquet-hadoop-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2a37d810\\9cabad55\\javafx-base-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\22491143\\b7ec7529\\javafx-controls-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\fd01b862\\d4aac73a\\javafx-fxml-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\5bc020c1\\71973935\\javafx-graphics-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9f861ca4\\59d74b78\\javafx-media-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\006a08f5\\2a962dca\\javafx-swing-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\de44e8e1\\760be701\\javafx-web-19-win.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7da338a0\\5a6bab09\\jackson-core-2.13.4.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\00d47e3c\\1edd89c2\\commons-compress-1.21.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\92dfff10\\9357b12c\\avro-ipc-1.11.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2dbc64bc\\dee2ac46\\kryo-shaded-4.0.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6f69d34b\\4de75456\\commons-logging-1.1.3.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\d4db9403\\a66253a7\\leveldbjni-all-1.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\0de4317f\\131d177b\\jackson-annotations-2.13.4.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\0cf6a733\\65dc2eec\\tink-1.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\bab2c247\\566b66cb\\curator-framework-2.13.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f25b0770\\d5598fe1\\commons-lang-2.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a8f14d4d\\f91e80b5\\zookeeper-jute-3.6.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e5b5e5ee\\d35d6459\\audience-annotations-0.12.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\c133f893\\b2598dd8\\shims-0.9.25.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\c65338cc\\3d17092a\\json4s-core_2.12-3.7.0-M11.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\525fca7e\\90129ce6\\jakarta.ws.rs-api-2.1.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\48509d9e\\947f08f9\\jakarta.inject-2.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ee0d7efa\\c41a5f48\\jakarta.annotation-api-1.3.5.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\5561f707\\687d9e69\\osgi-resource-locator-1.0.3.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1ebeaeea\\d9840d2b\\jakarta.validation-api-2.0.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\9eb7f7ec\\74ed8301\\hk2-locator-2.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\b9ccfc87\\97d79ced\\javassist-3.25.0-GA.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a8110a30\\794ccbb7\\netty-buffer-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ca93c5f3\\cf65896c\\netty-codec-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\573c4f2c\\192349ac\\netty-common-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\dd19078d\\2afb3654\\netty-handler-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8479fcb3\\58b579d6\\netty-tcnative-classes-2.0.48.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\afe89e89\\9e2127f1\\netty-resolver-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\b426e508\\231ef713\\netty-transport-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8c241553\\b62474a2\\netty-transport-classes-epoll-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\adf06c49\\de3026a0\\netty-transport-native-unix-common-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\ec4bf9ce\\91e16231\\netty-transport-classes-kqueue-4.1.74.Final.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\3108db8d\\b8cfc7c2\\netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\1d8a1a35\\76c5f0c9\\netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\0ab748c9\\c51997b5\\netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\92972cf7\\08b5253a\\netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e0f19672\\daed874d\\paranamer-2.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\fe516213\\65eed2b2\\scala-parser-combinators_2.12-1.1.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\c877690d\\17f9b3c5\\janino-3.0.16.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\cc6561f7\\c1fb197b\\commons-compiler-3.0.16.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a46cd51b\\f944761c\\antlr4-runtime-4.8.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\0c0298a0\\b03f2136\\arrow-vector-7.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\64b12ff3\\db9c906b\\arrow-memory-netty-7.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\bb403a2e\\8f04c36a\\orc-shims-1.7.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a2b5a599\\3eb00e50\\protobuf-java-3.14.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7b487c53\\e17074bd\\aircompressor-0.21.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\4a61e4c7\\4939cb74\\annotations-17.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8853c64d\\049906a4\\threeten-extra-1.5.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e09dc6d5\\624898a7\\parquet-common-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e847bfc1\\ca4616f1\\parquet-encoding-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\d9775888\\07c2c3d3\\parquet-format-structures-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\a52c4b1b\\367e0472\\parquet-jackson-1.12.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\09cd53d9\\8589d052\\xz-1.9.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\397291a5\\130f6609\\minlog-1.3.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2d27390e\\9428a2ae\\objenesis-2.5.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\b8963d22\\b2ff056b\\gson-2.8.6.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\badfc86b\\7c2fb6dc\\curator-client-2.13.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\91b60e7d\\e7e08085\\json4s-ast_2.12-3.7.0-M11.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\8aed64e6\\d84bffd0\\json4s-scalap_2.12-3.7.0-M11.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\7228aca1\\fd78eab4\\aopalliance-repackaged-2.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\f637b924\\6bac4616\\hk2-api-2.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\eb98b7bf\\7b471b39\\hk2-utils-2.6.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\6a6a996f\\3c9806a1\\arrow-format-7.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\5ff27638\\a5aec0d7\\arrow-memory-core-7.0.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\2aa925c0\\3c8b8022\\flatbuffers-java-1.12.0.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\dc1e0aeb\\fce55f79\\guava-16.0.1.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\e774afb7\\adaca685\\javax.annotation-api-1.3.2.jar\n\tC:\\Projects\\NOAAData\\noaadata\\target\\bg-jobs\\sbt_69d7f647\\target\\986a2916\\799ad191\\netty-transport-native-epoll-4.1.74.Final.jar"})[0m
[0m[[0m[31merror[0m] [0m[0mjava.lang.RuntimeException: Exception in Application start method[0m
[0m[[0m[31merror[0m] [0m[0m	at com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:917)[0m
[0m[[0m[31merror[0m] [0m[0m	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication$1(LauncherImpl.java:182)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Thread.java:750)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 1.0 failed 1 times, most recent failure: Lost task 6.0 in stage 1.0 (TID 18) (LAPTOP-1OB7IE1N executor driver): java.io.IOException: There is not enough space on the disk[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.IOUtil.write(IOUtil.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.writeFullyImpl(Channels.java:78)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.writeFully(Channels.java:101)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.access$000(Channels.java:61)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels$1.write(Channels.java:174)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1527)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1525)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:327)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Thread.java:750)[0m
[0m[[0m[31merror[0m] [0m[0m[0m
[0m[[0m[31merror[0m] [0m[0mDriver stacktrace:[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Option.foreach(Option.scala:274)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: java.io.IOException: There is not enough space on the disk[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.IOUtil.write(IOUtil.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.writeFullyImpl(Channels.java:78)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.writeFully(Channels.java:101)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels.access$000(Channels.java:61)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.nio.channels.Channels$1.write(Channels.java:174)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1527)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1525)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:327)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.Task.run(Task.scala:136)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Thread.java:750)[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"java.lang.RuntimeException: Exception in Application start method\r\n\tat com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:917)\r\n\tat com.sun.javafx.application.LauncherImpl.lambda$launchApplication$1(LauncherImpl.java:182)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 1.0 failed 1 times, most recent failure: Lost task 6.0 in stage 1.0 (TID 18) (LAPTOP-1OB7IE1N executor driver): java.io.IOException: There is not enough space on the disk\r\n\tat sun.nio.ch.FileDispatcherImpl.write0(Native Method)\r\n\tat sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)\r\n\tat sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)\r\n\tat sun.nio.ch.IOUtil.write(IOUtil.java:65)\r\n\tat sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)\r\n\tat org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)\r\n\tat java.nio.channels.Channels.writeFullyImpl(Channels.java:78)\r\n\tat java.nio.channels.Channels.writeFully(Channels.java:101)\r\n\tat java.nio.channels.Channels.access$000(Channels.java:61)\r\n\tat java.nio.channels.Channels$1.write(Channels.java:174)\r\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\r\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\r\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\r\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)\r\n\tat java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)\r\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)\r\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\r\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\r\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1527)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1525)\r\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\r\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:274)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.io.IOException: There is not enough space on the disk\r\n\tat sun.nio.ch.FileDispatcherImpl.write0(Native Method)\r\n\tat sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:75)\r\n\tat sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)\r\n\tat sun.nio.ch.IOUtil.write(IOUtil.java:65)\r\n\tat sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)\r\n\tat org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)\r\n\tat java.nio.channels.Channels.writeFullyImpl(Channels.java:78)\r\n\tat java.nio.channels.Channels.writeFully(Channels.java:101)\r\n\tat java.nio.channels.Channels.access$000(Channels.java:61)\r\n\tat java.nio.channels.Channels$1.write(Channels.java:174)\r\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\r\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\r\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\r\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)\r\n\tat java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)\r\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)\r\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\r\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\r\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1527)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1525)\r\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)\r\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\r\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)\r\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)\r\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)\r\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)"})[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) Exception in Application start method[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"(Compile / \u001b[31mrun\u001b[0m) Exception in Application start method"})[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 355 s (05:55), completed 13 Feb, 2023 11:21:23 AM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
