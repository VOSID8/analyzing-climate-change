[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Projects/NOAAData/noaadata/src/main/scala/Main.scala","languageId":"scala","version":1,"text":"package sparksql\r\n\r\nimport org.apache.spark.sql.SparkSession\r\nimport scalafx.application.JFXApp\r\nimport org.apache.spark.sql.types.StructType\r\nimport org.apache.spark.sql.types.StructField\r\nimport org.apache.spark.sql.types.StringType\r\nimport org.apache.spark.sql.types.DateType\r\nimport org.apache.spark.sql.types.DoubleType\r\nimport org.apache.spark.sql.Row\r\nimport org.apache.spark.sql.functions._\r\nimport swiftvis2.plotting._\r\nimport swiftvis2.plotting.renderer.FXRenderer\r\nimport swiftvis2.plotting.ColorGradient\r\nimport swiftvis2.plotting.renderer.SwingRenderer\r\n\r\n\r\nobject NOAAData extends JFXApp {\r\n  val spark = SparkSession.builder().master(\"local[*]\").appName(\"NOAA Data\").getOrCreate()\r\n  import spark.implicits._\r\n  \r\n  spark.sparkContext.setLogLevel(\"WARN\")\r\n  \r\n  val tschema = StructType(Array(\r\n      StructField(\"sid\",StringType),\r\n      StructField(\"date\",DateType),\r\n      StructField(\"mtype\",StringType),\r\n      StructField(\"value\",DoubleType)\r\n      ))\r\n  val data2022 = spark.read.schema(tschema).option(\"dateFormat\", \"yyyyMMdd\").csv(\"src/main/scala/data/2022.csv\").cache()\r\n  \r\n  val sschema = StructType(Array(\r\n      StructField(\"sid\", StringType),\r\n      StructField(\"lat\", DoubleType),\r\n      StructField(\"lon\", DoubleType),\r\n      StructField(\"name\", StringType)\r\n      ))\r\n  val stationRDD = spark.sparkContext.textFile(\"src/main/scala/data/ghcnd-stations.txt\").map { line =>\r\n    val id = line.substring(0, 11)\r\n    val lat = line.substring(12, 20).toDouble\r\n    val lon = line.substring(21, 30).toDouble\r\n    val name = line.substring(41, 71)\r\n    Row(id, lat, lon, name)\r\n  }\r\n  val stations = spark.createDataFrame(stationRDD, sschema).cache()\r\n  \r\n  val tmax2022 = data2022.filter($\"mtype\" === \"TMAX\").limit(1000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmax\")\r\n  val tmin2022 = data2022.filter('mtype === \"TMIN\").limit(1000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmin\")\r\n  val combinedTemps2022 = tmax2022.join(tmin2022, Seq(\"sid\", \"date\"))\r\n  val dailyTemp2022 = combinedTemps2022.select('sid, 'date, ('tmax - 'tmin)/10 as \"tave\")\r\n  val stationTemp2022 = dailyTemp2022.groupBy('sid).agg(avg('tave) as \"tave\")\r\n  val joinedData2022 = stationTemp2022.join(stations, \"sid\")\r\n\r\n  val lons = joinedData2022.select('lon).as[Double].collect()\r\n  val lats = joinedData2022.select('lat).as[Double].collect()\r\n  val taves = joinedData2022.select('tave).as[Double].collect()\r\n\r\n  {\r\n    implicit val df = joinedData2022\r\n    val cg = ColorGradient(5.0 -> BlueARGB, 10.0 -> GreenARGB, 15.0 -> RedARGB)\r\n    val plot = Plot.scatterPlot(lons, lats, title = \"Difference Temps 2022\", xLabel = \"Longitude\", \r\n        yLabel = \"Latitude\", symbolSize = 3, cg(taves))\r\n    SwingRenderer(plot, 800, 600, true)\r\n  }\r\n\r\nspark.stop()\r\n}\r\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
