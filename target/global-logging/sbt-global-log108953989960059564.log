[0m[[0m[0mdebug[0m] [0m[0m> Exec(run, Some(2d64f415-491c-4755-9ded-6b847dceeda0), Some(CommandSource(console0)))[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / run[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Projects/NOAAData/noaadata/src/main/scala/Ditemp1972.scala","languageId":"scala","version":1,"text":"\nimport org.apache.spark.sql.SparkSession\nimport scalafx.application.JFXApp\nimport org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.types.StructField\nimport org.apache.spark.sql.types.StringType\nimport org.apache.spark.sql.types.DateType\nimport org.apache.spark.sql.types.DoubleType\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.functions._\nimport swiftvis2.plotting._\nimport swiftvis2.plotting.ColorGradient\nimport swiftvis2.plotting.renderer.SwingRenderer\n\n\nobject Ditemp1972 extends JFXApp {\n  val spark = SparkSession.builder().master(\"local[*]\").appName(\"NOAA Data\").getOrCreate()\n  import spark.implicits._\n  \n  spark.sparkContext.setLogLevel(\"WARN\")\n  \n  val tschema = StructType(Array(\n      StructField(\"sid\",StringType),\n      StructField(\"date\",DateType),\n      StructField(\"mtype\",StringType),\n      StructField(\"value\",DoubleType)\n      ))\n    \n  val data2022 = spark.read.schema(tschema).option(\"dateFormat\", \"yyyyMMdd\").csv(\"src/main/scala/data/2022.csv\").cache()\n  val data1972 = spark.read.schema(tschema).option(\"dateFormat\", \"yyyyMMdd\").csv(\"src/main/scala/data/1972.csv\").cache()\n  \n  data2022.show()\n\n  val sschema = StructType(Array(\n      StructField(\"sid\", StringType),\n      StructField(\"lat\", DoubleType),\n      StructField(\"lon\", DoubleType),\n      StructField(\"name\", StringType)\n      ))\n  val stationRDD = spark.sparkContext.textFile(\"src/main/scala/data/ghcnd-stations.txt\").map { line =>\n    val id = line.substring(0, 11)\n    val lat = line.substring(12, 20).toDouble\n    val lon = line.substring(21, 30).toDouble\n    val name = line.substring(41, 71)\n    Row(id, lat, lon, name)\n  }\n\n  val stations = spark.createDataFrame(stationRDD, sschema).cache()\n  \n  val tmax2022 = data2022.filter($\"mtype\" === \"TMAX\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmax\")\n\n  tmax2022.show()\n\n  val tmin2022 = data2022.filter('mtype === \"TMIN\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmin\")\n  val combinedTemps2022 = tmax2022.join(tmin2022, Seq(\"sid\", \"date\"))\n  val dailyTemp2022 = combinedTemps2022.select('sid, 'date, ('tmax - 'tmin)/10 as \"tave2022\")\n  val stationTemp2022 = dailyTemp2022.groupBy('sid).agg(avg('tave2022) as \"tave2022\")\n  val joinedData2022 = stationTemp2022.join(stations, \"sid\")\n\n  val tmax1972 = data1972.filter($\"mtype\" === \"TMAX\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmax\")\n  val tmin1972 = data1972.filter('mtype === \"TMIN\").limit(10000000).drop(\"mtype\").withColumnRenamed(\"value\", \"tmin\")\n  val combinedTemps1972 = tmax1972.join(tmin1972, Seq(\"sid\", \"date\"))\n  val dailyTemp1972 = combinedTemps1972.select('sid, 'date, ('tmax - 'tmin)/10 as \"tave1972\")\n  val stationTemp1972 = dailyTemp1972.groupBy('sid).agg(avg('tave1972) as \"tave1972\")\n\n  val combinedData = stationTemp1972.join(joinedData2022,\"sid\")\n\n  combinedData.show()\n  combinedData.schema.printTreeString()\n  \n  \n  val filteredData = combinedData.select('lon, 'lat, 'tave1972,'tave2022).as[(Double, Double, Double,Double)].collect()\n  //val redpoints = joinedData2022.filter('tave >= 17.0).select('lon, 'lat, 'tave).as[(Double, Double, Double)].collect()\n  //val bluepoints = joinedData2022.filter('tave <= 7.0).select('lon, 'lat, 'tave).as[(Double, Double, Double)].collect()\n  //val greenpoints = joinedData2022.filter('tave > 7.0 && 'tave < 17).select('lon, 'lat, 'tave).as[(Double, Double, Double)].collect()\n  \n  \n  \n  \n  // val sizeredpoints1972 = filteredData.count(_._3 > 16.0)\n  // val sizebluepoints1972 = filteredData.count(_._3 <= 10.0)\n  // val sizegreenpoints1972 = filteredData.count(_._3 > 10.0) - sizeredpoints1972\n\n  // val sizeredpoints2022 = filteredData.count(_._4 > 16.0)\n  // val sizebluepoints2022 = filteredData.count(_._4 <= 10.0)\n  // val sizegreenpoints2022 = filteredData.count(_._4 > 10.0) - sizeredpoints2022\n  // println(sizeredpoints1972)\n  // println(sizebluepoints1972)\n  // println(sizegreenpoints1972)\n\n  // println(sizeredpoints2022)\n  // println(sizebluepoints2022)\n  // println(sizegreenpoints2022)\n\n  // val lons = combinedData.select('lon).as[Double].collect()\n  // val lats = combinedData.select('lat).as[Double].collect()\n  // val taves1972 = combinedData.select('tave1972).as[Double].collect()\n  // val taves2022 = combinedData.select('tave2022).as[Double].collect()\n\n  // {\n    // val cg = ColorGradient(6.0 -> BlueARGB, 10.0 -> GreenARGB, 16.0 -> RedARGB)\n    // val plot = Plot.scatterPlot(lons, lats, title = \"Diurnal Temps 1972\", xLabel = \"Longitude\", \n    // yLabel = \"Latitude\", symbolSize = 3, cg(taves1972))\n    // SwingRenderer(plot, 800, 600)\n  // }\n  // {\n    // val cg = ColorGradient(6.0 -> BlueARGB, 10.0 -> GreenARGB, 16.0 -> RedARGB)\n    // val plot = Plot.scatterPlot(lons, lats, title = \"Diurnal Temps 2022\", xLabel = \"Longitude\", \n    // yLabel = \"Latitude\", symbolSize = 3, cg(taves2022))\n    // SwingRenderer(plot, 800, 600)\n  // }\n\nspark.stop()\n}\n\n"}})[0m
[0m[[0m[31merror[0m] [0m[0mjava.lang.RuntimeException: Exception in Application start method[0m
[0m[[0m[31merror[0m] [0m[0m	at com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:917)[0m
[0m[[0m[31merror[0m] [0m[0m	at com.sun.javafx.application.LauncherImpl.lambda$launchApplication$1(LauncherImpl.java:182)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Thread.java:750)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: org.apache.spark.sql.AnalysisException: Path does not exist: file:/C:/Projects/NOAAData/noaadata/src/main/scala/data/2022.csv[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.errors.QueryCompilationErrors$.dataPathNotExistError(QueryCompilationErrors.scala:1011)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:785)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:658)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Success.$anonfun$map$1(Try.scala:255)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Success.map(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1067)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1703)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:172)[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"java.lang.RuntimeException: Exception in Application start method\r\n\tat com.sun.javafx.application.LauncherImpl.launchApplication1(LauncherImpl.java:917)\r\n\tat com.sun.javafx.application.LauncherImpl.lambda$launchApplication$1(LauncherImpl.java:182)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.spark.sql.AnalysisException: Path does not exist: file:/C:/Projects/NOAAData/noaadata/src/main/scala/data/2022.csv\r\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.dataPathNotExistError(QueryCompilationErrors.scala:1011)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:785)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:782)\r\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:372)\r\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:658)\r\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\r\n\tat scala.util.Success.map(Try.scala:213)\r\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\r\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\r\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\r\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\r\n\tat java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\r\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\r\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1067)\r\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1703)\r\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:172)"})[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) Exception in Application start method[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"(Compile / \u001b[31mrun\u001b[0m) Exception in Application start method"})[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 32 s, completed 27 Mar, 2023 10:42:59 AM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
